# ğŸ¦ Twitter Sentiment Analysis

## ğŸ“Œ Overview

This project builds an end-to-end Natural Language Processing (NLP) pipeline to classify tweets as **positive** or **negative** using supervised machine learning techniques. It demonstrates practical text preprocessing, feature engineering, model training, and evaluation on large-scale social media data.

---

## ğŸ“‚ Dataset

The dataset used in this project is the **Sentiment140 dataset** from Kaggle:

ğŸ”— https://www.kaggle.com/datasets/kazanova/sentiment140

The dataset contains 1.6 million labeled tweets.
Each record includes:

* **target** â€“ Tweet polarity (`0 = Negative`, `4 = Positive`)
* **id** â€“ Unique tweet identifier
* **date** â€“ Timestamp of the tweet
* **flag** â€“ Query associated with the tweet (`NO_QUERY` if none)
* **user** â€“ Username of the tweet author
* **text** â€“ The content of the tweet

---

## âš™ï¸ Methodology

### ğŸ”¹ Data Preprocessing

* Text cleaning (removing punctuation, URLs, special characters)
* Lowercasing
* Stopword removal
* Tokenization

### ğŸ”¹ Feature Engineering

* Text vectorization using CountVectorizer / TF-IDF
* Conversion of tweet text into numerical feature vectors

### ğŸ”¹ Model Training

* Supervised machine learning classifier trained on labeled tweet data

---

## ğŸ“Š Model Evaluation

### ğŸ”¹ Accuracy

* **Training Accuracy:** 79.87%
* **Test Accuracy:** 77.67%

The small gap (~2%) between training and test accuracy indicates good generalization with no significant overfitting.

---

### ğŸ”¹ Classification Report (Test Data)

| Class        | Precision | Recall | F1-Score | Support |
| ------------ | --------- | ------ | -------- | ------- |
| 0 (Negative) | 0.79      | 0.76   | 0.77     | 160,000 |
| 1 (Positive) | 0.77      | 0.80   | 0.78     | 160,000 |

* **Overall Accuracy:** 78%
* **Macro Average F1-Score:** 0.78
* **Weighted Average F1-Score:** 0.78

---

### ğŸ”¹ Interpretation

* The model achieves balanced performance across both sentiment classes.
* Precision and recall values are consistent, indicating stable classification behavior.
* Similar training and testing accuracy suggests the model is not overfitting.
* Performance is solid for a classical machine learning approach on noisy social media text.

---

## ğŸš€ Future Improvements

* Hyperparameter tuning
* Use of n-grams and advanced vectorization techniques
* Implementation of deep learning models (LSTM / GRU)
* Transformer-based models (BERT)
* Deployment as an API or web application

---

## ğŸ›  Tech Stack

* Python
* Pandas & NumPy
* Scikit-learn
* NLP preprocessing techniques
* Jupyter Notebook

---

## ğŸ’¡ Key Takeaways

* Large-scale text classification implementation
* Practical NLP pipeline development
* Balanced sentiment prediction performance
* Strong baseline model with room for advanced improvements
* This implementation is based on a tutorial from GeeksforGeeks and was developed for practice purposes.

---
